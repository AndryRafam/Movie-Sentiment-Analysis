{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f7fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7133bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one reviewers mentioned watching oz episode hooked right exactly happened me br br the first thing struck oz brutality unflinching scenes violence set right word go trust me show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word br br it called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish more so scuffles death stares dodgy dealings shady agreements never far away br br i would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready it watched more developed taste oz got accustomed high levels graphic violence violence injustice crooked guards who ll sold nickel inmates who ll kill order get away it well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side ', 'wonderful little production br br the filming technique unassuming old time bbc fashion gives comforting sometimes discomforting sense realism entire piece br br the actors extremely well chosen michael sheen has got polari voices pat too truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master s comedy life br br the realism really comes home little things fantasy guard which rather use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell s murals decorating every surface terribly well done ', 'thought wonderful way spend time hot summer weekend sitting air conditioned theater watching light hearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point risk addiction thought proof woody allen still fully control style many us grown love br br this i d laughed one woody s comedies years dare say decade i ve never impressed scarlet johanson managed tone sexy image jumped right average spirited young woman br br this may crown jewel career wittier devil wears prada interesting superman great comedy go see friends ', 'basically there s family little boy jake thinks there s zombie closet parents fighting time br br this movie slower soap opera suddenly jake decides become rambo kill zombie br br ok first going make film must decide thriller drama drama movie watchable parents divorcing arguing like real life jake closet totally ruins film expected see boogeyman similar movie instead watched drama meaningless thriller spots br br well playing parents descent dialogs shots jake ignore them ', 'petter mattei s love time money visually stunning film watch mr mattei offers us vivid portrait human relations movie seems telling us money power success people different situations encounter br br this variation arthur schnitzler s play theme director transfers action present time new york different characters meet connect one connected one way another next person one seems know previous point contact stylishly film sophisticated luxurious look taken see people live world live habitat br br the thing one gets souls picture different stages loneliness one inhabits big city exactly best place human relations find sincere fulfillment one discerns case people encounter br br the acting good mr mattei s direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier rest talented cast make characters come alive br br we wish mr mattei good luck await anxiously next work ']\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "directory = \"/home/maverick/MovieSentiment/Main/imdb.csv\"\n",
    "data = pd.read_csv(directory)\n",
    "stop_words = stopwords.words(\"english\")\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "def text_preproc(x):\n",
    "\tx = x.lower()\n",
    "\tx = \" \".join([word for word in x.split(\" \") if word not in stop_words])\n",
    "\tx = x.encode(\"ascii\", \"ignore\").decode()\n",
    "\tx = re.sub(r\"https*\\S+\", \" \", x)\n",
    "\tx = re.sub(r\"@\\S+\", \" \", x)\n",
    "\tx = re.sub(r\"#\\S+\", \" \", x)\n",
    "\tx = re.sub(r\"\\\",\\w+\", \"\", x)\n",
    "\tx = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", x)\n",
    "\tx = re.sub(r\"\\w*\\d+\\w*\", \"\", x)\n",
    "\tx = re.sub(r\"\\s{2,}\", \" \", x)\n",
    "\treturn x\n",
    "\t\n",
    "final_data = []\n",
    "data_to_list = data[\"review\"].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "\tfinal_data.append(text_preproc(data_to_list[i]))\n",
    "print(list(final_data[:5]))\n",
    "\n",
    "final_data = np.array(final_data)\n",
    "\n",
    "labels = np.array(data[\"sentiment\"])\n",
    "l = []\n",
    "for i in range(len(labels)):\n",
    "\tif labels[i]==\"negative\":\n",
    "\t\tl.append(0)\n",
    "\telif labels[i]==\"positive\":\n",
    "\t\tl.append(1)\n",
    "l = np.array(l)\n",
    "labels = tf.keras.utils.to_categorical(l,2,dtype=\"int32\")\n",
    "del l\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16947355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8383372b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 1136 4035  404]\n",
      " [   0    0    0 ... 1906   17  131]\n",
      " [   0    0    0 ...   61   16  267]\n",
      " ...\n",
      " [   0    0    0 ... 3923    2 5882]\n",
      " [   0    0    0 ... 4121  655  615]\n",
      " [   0    0    0 ... 4383  712    3]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "28125 9375 12500 28125 9375 12500\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,757,890\n",
      "Trainable params: 2,757,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "879/879 [==============================] - 44s 45ms/step - loss: 0.3647 - accuracy: 0.8415 - val_loss: 0.2790 - val_accuracy: 0.8807\n",
      "Epoch 2/3\n",
      "879/879 [==============================] - 39s 44ms/step - loss: 0.1868 - accuracy: 0.9327 - val_loss: 0.3231 - val_accuracy: 0.8703\n",
      "Epoch 3/3\n",
      "879/879 [==============================] - 41s 46ms/step - loss: 0.1178 - accuracy: 0.9607 - val_loss: 0.3843 - val_accuracy: 0.8668\n"
     ]
    }
   ],
   "source": [
    "max_words = 20000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(final_data)\n",
    "sequences = tokenizer.texts_to_sequences(final_data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "with open(\"tockenizer.pickle\",\"wb\") as handle:\n",
    "\tpickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)\t\n",
    "print(tweets)\n",
    "print(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweets,labels,random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "print(len(x_train),len(x_val),len(x_test),len(y_train),len(y_val),len(y_test))\n",
    "\n",
    "model = Sequential([\n",
    "\tlayers.Embedding(max_words,128,input_length=max_len),\n",
    "\tlayers.Bidirectional(layers.LSTM(64,return_sequences=True)),\n",
    "\tlayers.Bidirectional(layers.LSTM(64)),\n",
    "\tlayers.Dense(2,activation=\"softmax\"),\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "checkpoint = ModelCheckpoint(\"model_best.hdf5\", save_best_only=True, save_weights_only=False)\n",
    "history = model.fit(x_train, y_train, epochs=3, validation_data=(x_val,y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed04670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 - 6s - loss: 0.2732 - accuracy: 0.8847\n",
      "Model accuracy: 88.47 %\n"
     ]
    }
   ],
   "source": [
    "model_best = tf.keras.models.load_model(\"model_best.hdf5\")\n",
    "test_loss, test_acc, = model_best.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Model accuracy: {:.2f} %\".format(100*test_acc))\n",
    "predictions = model_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42246e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
