{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04b9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12dcc591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of the other reviewers has mentioned that after watching just oz episode you be hooked they are right as this is exactly what happened with me br br the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the word br br it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to many aryans muslims gangstas latinos christians italians irish and more so scuffles death stares dodgy dealings and shady agreements are never far away br br would say the main appeal of the show is due to the fact that it goes where other shows wouldn dare forget pretty pictures painted for mainstream audiences forget charm forget romance oz doesn mess around the first episode ever saw struck me as so nasty it was surreal couldn say was ready for it but as watched more developed taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards who be sold out for nickel inmates who kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewing thats if you can get in touch with your darker side', 'wonderful little production br br the filming technique is very unassuming very old time bbc fashion and gives comforting and sometimes discomforting sense of realism to the entire piece br br the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is terrificly written and performed piece masterful production about one of the great master of comedy and his life br br the realism really comes home with the little things the fantasy of the guard which rather than use the traditional techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwell murals decorating every surface are terribly well done', 'thought this was wonderful way to spend time on too hot summer weekend sitting in the air conditioned theater and watching light hearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point risk addiction thought it was proof that woody allen is still fully in control of the style many of us have grown to love br br this was the most laughed at one of woody comedies in years dare say decade while never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into average but spirited young woman br br this may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman great comedy to go see with friends', 'basically there family where little boy jake thinks there zombie in his closet his parents are fighting all the time br br this movie is slower than soap opera and suddenly jake decides to become rambo and kill the zombie br br ok first of all when you going to make film you must decide if its thriller or drama as drama the movie is watchable parents are divorcing arguing like in real life and then we have jake with his closet which totally ruins all the film expected to see boogeyman similar movie and instead watched drama with some meaningless thriller spots br br out of just for the well playing parents descent dialogs as for the shots with jake just ignore them', 'petter mattei love in the time of money is visually stunning film to watch mr mattei offers us vivid portrait about human relations this is movie that seems to be telling us what money power and success do to people in the different situations we encounter br br this being variation on the arthur schnitzler play about the same theme the director transfers the action to the present time new york where all these different characters meet and connect each one is connected in one way or another to the next person but no one seems to know the previous point of contact stylishly the film has sophisticated luxurious look we are taken to see how these people live and the world they live in their own habitat br br the only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits big city is not exactly the best place in which human relations find sincere fulfillment as one discerns is the case with most of the people we encounter br br the acting is good under mr mattei direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier and the rest of the talented cast make these characters come alive br br we wish mr mattei good luck and await anxiously for his next work']\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "#nltk.download(\"wordnet\")\n",
    "# Directory to the dataset. (User can change it at will according their own download directory.)\n",
    "directory = \"imdb.csv\"\n",
    "\n",
    "df = pd.read_csv(directory)\n",
    "#stop_words = set(stopwords.words(\"english\"))\n",
    "#wordnet = WordNetLemmatizer()\n",
    "\n",
    "def text_preproc(x):\n",
    "\tx = x.lower()\n",
    "\t#x = \" \".join([word for word in x.split(\" \") if word not in stop_words])\n",
    "\tx = x.encode(\"ascii\", \"ignore\").decode()\n",
    "\tx = re.sub(\"https*\\S+\", \" \", x)\n",
    "\tx = re.sub(\"@\\S+\", \" \", x)\n",
    "\tx = re.sub(\"#\\S+\", \" \", x)\n",
    "\tx = re.sub(\"\\'\\w+\", \"\", x)\n",
    "\tx = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", x)\n",
    "\tx = re.sub(\"\\w*\\d+\\w*\", \"\", x)\n",
    "\tx = re.sub(\"\\s{2,}\", \" \", x)\n",
    "\treturn x\n",
    "\t\n",
    "temp = []\n",
    "data_to_list = df[\"review\"].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "\ttemp.append(text_preproc(data_to_list[i]))\n",
    "\n",
    "def tokenize(y):\n",
    "\tfor x in y:\n",
    "\t\tyield(simple_preprocess(str(x)))\n",
    "\n",
    "data_words = list(tokenize(temp))\n",
    "\n",
    "def detokenize(txt):\n",
    "\treturn TreebankWordDetokenizer().detokenize(txt)\n",
    "\t\n",
    "final_data = []\n",
    "for i in range(len(data_words)):\n",
    "\tfinal_data.append(detokenize(data_words[i]))\n",
    "print(final_data[:5])\n",
    "final_data = np.array(final_data)\n",
    "\n",
    "labels = np.array(df[\"sentiment\"])\n",
    "l = []\n",
    "for i in range(len(labels)):\n",
    "\tif labels[i]==\"negative\":\n",
    "\t\tl.append(0)\n",
    "\telif labels[i]==\"positive\":\n",
    "\t\tl.append(1)\n",
    "l = np.array(l)\n",
    "labels = tf.keras.utils.to_categorical(l,2,dtype=\"int32\")\n",
    "del l\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55982a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1 11386   347 ...   123  4036   469]\n",
      " [    0     0     0 ...  1930    66   213]\n",
      " [    0     0     0 ...    62    15   340]\n",
      " ...\n",
      " [ 9972  3363    16 ...  3906     2  5855]\n",
      " [    4    24     4 ...    47   714    41]\n",
      " [    0     0     0 ...   768     9    13]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "28125 9375 12500 28125 9375 12500\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,757,890\n",
      "Trainable params: 2,757,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "879/879 - 41s - loss: 0.3817 - accuracy: 0.8277 - val_loss: 0.2987 - val_accuracy: 0.8804\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88043, saving model to model_bilstm.hdf5\n",
      "Epoch 2/3\n",
      "879/879 - 37s - loss: 0.2067 - accuracy: 0.9211 - val_loss: 0.3137 - val_accuracy: 0.8719\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.88043\n",
      "Epoch 3/3\n",
      "879/879 - 37s - loss: 0.1270 - accuracy: 0.9556 - val_loss: 0.3548 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.88043\n",
      "391/391 [==============================] - 6s 13ms/step - loss: 0.2938 - accuracy: 0.8806\n",
      "Test accuracy: 88.06 %\n",
      "Test loss: 29.38 %\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_words = 20000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(final_data)\n",
    "sequences = tokenizer.texts_to_sequences(final_data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "with open(\"tockenizer.pickle\",\"wb\") as handle:\n",
    "\tpickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)\t\n",
    "print(tweets)\n",
    "print(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweets,labels,random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "print(len(x_train),len(x_val),len(x_test),len(y_train),len(y_val),len(y_test))\n",
    "\n",
    "model = Sequential([\n",
    "\tlayers.Embedding(max_words,128,input_length=max_len),\n",
    "\tlayers.Bidirectional(layers.LSTM(64,return_sequences=True)),\n",
    "\tlayers.Bidirectional(layers.LSTM(64)),\n",
    "\tlayers.Dense(2,activation=\"softmax\"),\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "checkpoint = ModelCheckpoint(\"model_bilstm.hdf5\", monitor=\"val_accuracy\", verbose=1, save_best_only=True, save_weights_only=False)\n",
    "history = model.fit(x_train, y_train, epochs=3, validation_data=(x_val,y_val), verbose=2, callbacks=[checkpoint])\n",
    "\n",
    "model_bilstm = tf.keras.models.load_model(\"model_bilstm.hdf5\")\n",
    "test_loss, test_acc, = model_bilstm.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy: {:.2f} %\".format(100*test_acc))\n",
    "print(\"Test loss: {:.2f} %\".format(100*test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
